{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generating Fake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Data\n",
    "- An experimental Drug was tested on individuals from ages 13 to 100 in a clinical trial\n",
    "- The trial had 2100 participants. Half were under 65 years old, half were above 65\n",
    "- Around 95% of the participants >= 65 experienced side effects\n",
    "- around 95% of the participants < 65  experienced no side effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels, train_samples = shuffle(train_labels, train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66, 58, 37, ..., 84, 89, 98])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scalar.fit_transform(train_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Simple tf.keras Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print('Num GPUs Available: ', len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense is the first Hidden Layer (FULLY CONNECTED LAYER)\n",
    "# There is a hidden input layer that is not explicitly specified here\n",
    "# it is inferred from the input_shape\n",
    "# First hidden layer has 16 neurons\n",
    "# Second hidden layer has 32 neurons\n",
    "# Output layer has 2 neurons (2 possible outputs side effects or not)\n",
    "model = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "210/210 [==============================] - 0s 551us/step - loss: 0.2469 - accuracy: 0.9419\n",
      "Epoch 2/30\n",
      "210/210 [==============================] - 0s 544us/step - loss: 0.2465 - accuracy: 0.9419\n",
      "Epoch 3/30\n",
      "210/210 [==============================] - 0s 556us/step - loss: 0.2461 - accuracy: 0.9419\n",
      "Epoch 4/30\n",
      "210/210 [==============================] - 0s 545us/step - loss: 0.2459 - accuracy: 0.9419\n",
      "Epoch 5/30\n",
      "210/210 [==============================] - 0s 545us/step - loss: 0.2454 - accuracy: 0.9419\n",
      "Epoch 6/30\n",
      "210/210 [==============================] - 0s 535us/step - loss: 0.2452 - accuracy: 0.9443\n",
      "Epoch 7/30\n",
      "210/210 [==============================] - 0s 532us/step - loss: 0.2448 - accuracy: 0.9419\n",
      "Epoch 8/30\n",
      "210/210 [==============================] - 0s 569us/step - loss: 0.2446 - accuracy: 0.9419\n",
      "Epoch 9/30\n",
      "210/210 [==============================] - 0s 552us/step - loss: 0.2442 - accuracy: 0.9419\n",
      "Epoch 10/30\n",
      "210/210 [==============================] - 0s 541us/step - loss: 0.2440 - accuracy: 0.9419\n",
      "Epoch 11/30\n",
      "210/210 [==============================] - 0s 574us/step - loss: 0.2437 - accuracy: 0.9419\n",
      "Epoch 12/30\n",
      "210/210 [==============================] - 0s 588us/step - loss: 0.2436 - accuracy: 0.9438\n",
      "Epoch 13/30\n",
      "210/210 [==============================] - 0s 603us/step - loss: 0.2432 - accuracy: 0.9419\n",
      "Epoch 14/30\n",
      "210/210 [==============================] - 0s 558us/step - loss: 0.2429 - accuracy: 0.9419\n",
      "Epoch 15/30\n",
      "210/210 [==============================] - 0s 541us/step - loss: 0.2428 - accuracy: 0.9429\n",
      "Epoch 16/30\n",
      "210/210 [==============================] - 0s 536us/step - loss: 0.2425 - accuracy: 0.9443\n",
      "Epoch 17/30\n",
      "210/210 [==============================] - 0s 560us/step - loss: 0.2422 - accuracy: 0.9424\n",
      "Epoch 18/30\n",
      "210/210 [==============================] - 0s 563us/step - loss: 0.2422 - accuracy: 0.9433\n",
      "Epoch 19/30\n",
      "210/210 [==============================] - 0s 567us/step - loss: 0.2418 - accuracy: 0.9443\n",
      "Epoch 20/30\n",
      "210/210 [==============================] - 0s 546us/step - loss: 0.2416 - accuracy: 0.9419\n",
      "Epoch 21/30\n",
      "210/210 [==============================] - 0s 545us/step - loss: 0.2414 - accuracy: 0.9443\n",
      "Epoch 22/30\n",
      "210/210 [==============================] - 0s 663us/step - loss: 0.2412 - accuracy: 0.9476\n",
      "Epoch 23/30\n",
      "210/210 [==============================] - 0s 545us/step - loss: 0.2411 - accuracy: 0.9419\n",
      "Epoch 24/30\n",
      "210/210 [==============================] - 0s 545us/step - loss: 0.2408 - accuracy: 0.9452\n",
      "Epoch 25/30\n",
      "210/210 [==============================] - 0s 541us/step - loss: 0.2406 - accuracy: 0.9462\n",
      "Epoch 26/30\n",
      "210/210 [==============================] - 0s 536us/step - loss: 0.2405 - accuracy: 0.9452\n",
      "Epoch 27/30\n",
      "210/210 [==============================] - 0s 550us/step - loss: 0.2404 - accuracy: 0.9481\n",
      "Epoch 28/30\n",
      "210/210 [==============================] - 0s 555us/step - loss: 0.2404 - accuracy: 0.9443\n",
      "Epoch 29/30\n",
      "210/210 [==============================] - 0s 536us/step - loss: 0.2399 - accuracy: 0.9429\n",
      "Epoch 30/30\n",
      "210/210 [==============================] - 0s 560us/step - loss: 0.2398 - accuracy: 0.9448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c79be7e3a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle gets rid of any order that was present in the train data before being passed on to the model\n",
    "model.fit(x=scaled_train_samples,\n",
    "          y=train_labels,\n",
    "          batch_size=10,\n",
    "          epochs=30,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.9444 - val_loss: 0.1884 - val_accuracy: 0.9619\n",
      "Epoch 2/30\n",
      "189/189 [==============================] - 0s 670us/step - loss: 0.2453 - accuracy: 0.9513 - val_loss: 0.1876 - val_accuracy: 0.9619\n",
      "Epoch 3/30\n",
      "189/189 [==============================] - 0s 654us/step - loss: 0.2450 - accuracy: 0.9460 - val_loss: 0.1876 - val_accuracy: 0.9619\n",
      "Epoch 4/30\n",
      "189/189 [==============================] - 0s 649us/step - loss: 0.2450 - accuracy: 0.9471 - val_loss: 0.1864 - val_accuracy: 0.9619\n",
      "Epoch 5/30\n",
      "189/189 [==============================] - 0s 640us/step - loss: 0.2446 - accuracy: 0.9460 - val_loss: 0.1879 - val_accuracy: 0.9619\n",
      "Epoch 6/30\n",
      "189/189 [==============================] - 0s 652us/step - loss: 0.2445 - accuracy: 0.9503 - val_loss: 0.1862 - val_accuracy: 0.9619\n",
      "Epoch 7/30\n",
      "189/189 [==============================] - 0s 622us/step - loss: 0.2443 - accuracy: 0.9434 - val_loss: 0.1870 - val_accuracy: 0.9619\n",
      "Epoch 8/30\n",
      "189/189 [==============================] - 0s 666us/step - loss: 0.2441 - accuracy: 0.9450 - val_loss: 0.1864 - val_accuracy: 0.9619\n",
      "Epoch 9/30\n",
      "189/189 [==============================] - 0s 653us/step - loss: 0.2440 - accuracy: 0.9487 - val_loss: 0.1865 - val_accuracy: 0.9619\n",
      "Epoch 10/30\n",
      "189/189 [==============================] - 0s 673us/step - loss: 0.2437 - accuracy: 0.9439 - val_loss: 0.1876 - val_accuracy: 0.9619\n",
      "Epoch 11/30\n",
      "189/189 [==============================] - 0s 625us/step - loss: 0.2435 - accuracy: 0.9508 - val_loss: 0.1872 - val_accuracy: 0.9619\n",
      "Epoch 12/30\n",
      "189/189 [==============================] - 0s 650us/step - loss: 0.2433 - accuracy: 0.9460 - val_loss: 0.1867 - val_accuracy: 0.9619\n",
      "Epoch 13/30\n",
      "189/189 [==============================] - 0s 642us/step - loss: 0.2432 - accuracy: 0.9513 - val_loss: 0.1866 - val_accuracy: 0.9619\n",
      "Epoch 14/30\n",
      "189/189 [==============================] - 0s 649us/step - loss: 0.2430 - accuracy: 0.9444 - val_loss: 0.1871 - val_accuracy: 0.9619\n",
      "Epoch 15/30\n",
      "189/189 [==============================] - 0s 644us/step - loss: 0.2430 - accuracy: 0.9508 - val_loss: 0.1855 - val_accuracy: 0.9619\n",
      "Epoch 16/30\n",
      "189/189 [==============================] - 0s 647us/step - loss: 0.2428 - accuracy: 0.9513 - val_loss: 0.1851 - val_accuracy: 0.9619\n",
      "Epoch 17/30\n",
      "189/189 [==============================] - 0s 646us/step - loss: 0.2427 - accuracy: 0.9487 - val_loss: 0.1857 - val_accuracy: 0.9619\n",
      "Epoch 18/30\n",
      "189/189 [==============================] - 0s 648us/step - loss: 0.2427 - accuracy: 0.9503 - val_loss: 0.1861 - val_accuracy: 0.9619\n",
      "Epoch 19/30\n",
      "189/189 [==============================] - 0s 658us/step - loss: 0.2425 - accuracy: 0.9471 - val_loss: 0.1851 - val_accuracy: 0.9619\n",
      "Epoch 20/30\n",
      "189/189 [==============================] - 0s 654us/step - loss: 0.2423 - accuracy: 0.9466 - val_loss: 0.1857 - val_accuracy: 0.9619\n",
      "Epoch 21/30\n",
      "189/189 [==============================] - 0s 645us/step - loss: 0.2422 - accuracy: 0.9492 - val_loss: 0.1854 - val_accuracy: 0.9619\n",
      "Epoch 22/30\n",
      "189/189 [==============================] - 0s 690us/step - loss: 0.2421 - accuracy: 0.9503 - val_loss: 0.1838 - val_accuracy: 0.9619\n",
      "Epoch 23/30\n",
      "189/189 [==============================] - 0s 643us/step - loss: 0.2419 - accuracy: 0.9434 - val_loss: 0.1854 - val_accuracy: 0.9619\n",
      "Epoch 24/30\n",
      "189/189 [==============================] - 0s 677us/step - loss: 0.2418 - accuracy: 0.9513 - val_loss: 0.1848 - val_accuracy: 0.9619\n",
      "Epoch 25/30\n",
      "189/189 [==============================] - 0s 649us/step - loss: 0.2415 - accuracy: 0.9513 - val_loss: 0.1836 - val_accuracy: 0.9619\n",
      "Epoch 26/30\n",
      "189/189 [==============================] - 0s 666us/step - loss: 0.2417 - accuracy: 0.9439 - val_loss: 0.1845 - val_accuracy: 0.9619\n",
      "Epoch 27/30\n",
      "189/189 [==============================] - 0s 667us/step - loss: 0.2415 - accuracy: 0.9455 - val_loss: 0.1853 - val_accuracy: 0.9619\n",
      "Epoch 28/30\n",
      "189/189 [==============================] - 0s 654us/step - loss: 0.2414 - accuracy: 0.9497 - val_loss: 0.1846 - val_accuracy: 0.9619\n",
      "Epoch 29/30\n",
      "189/189 [==============================] - 0s 659us/step - loss: 0.2412 - accuracy: 0.9471 - val_loss: 0.1848 - val_accuracy: 0.9619\n",
      "Epoch 30/30\n",
      "189/189 [==============================] - 0s 664us/step - loss: 0.2411 - accuracy: 0.9455 - val_loss: 0.1854 - val_accuracy: 0.9619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c79beed820>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split 10% of training set as validation set\n",
    "# Note validation set is the last 10% of the training set\n",
    "model.fit(x=scaled_train_samples,\n",
    "          y=train_labels,\n",
    "          batch_size=10,\n",
    "          epochs=30,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Creating Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_samples = []\n",
    "\n",
    "for i in range(10):\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "\n",
    "for i in range(200):\n",
    "    \n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)\n",
    "test_labels, test_samples = shuffle(test_labels, test_samples)\n",
    "\n",
    "scaled_test_samples = scalar.fit_transform(test_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x=scaled_test_samples, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95738006 0.04262   ]\n",
      " [0.07714276 0.9228572 ]\n",
      " [0.05869924 0.94130075]\n",
      " [0.9638545  0.03614544]\n",
      " [0.100761   0.89923906]\n",
      " [0.0368554  0.9631446 ]\n",
      " [0.0106346  0.98936546]\n",
      " [0.9601548  0.03984525]\n",
      " [0.95878977 0.04121028]\n",
      " [0.02294223 0.9770578 ]\n",
      " [0.9591351  0.04086489]\n",
      " [0.07714276 0.9228572 ]\n",
      " [0.9627558  0.03724413]\n",
      " [0.04048376 0.9595162 ]\n",
      " [0.01894826 0.9810517 ]\n",
      " [0.96114993 0.03885002]\n",
      " [0.9594777  0.04052226]\n",
      " [0.9638545  0.03614544]\n",
      " [0.20480862 0.79519135]\n",
      " [0.9544094  0.04559061]\n",
      " [0.96389496 0.0361051 ]\n",
      " [0.09224965 0.9077503 ]\n",
      " [0.95975304 0.04024693]\n",
      " [0.02775422 0.9722457 ]\n",
      " [0.05352941 0.9464706 ]\n",
      " [0.95878977 0.04121028]\n",
      " [0.9591351  0.04086489]\n",
      " [0.2567836  0.74321634]\n",
      " [0.95347345 0.04652654]\n",
      " [0.05869924 0.94130075]\n",
      " [0.45475072 0.5452493 ]\n",
      " [0.02775422 0.9722457 ]\n",
      " [0.9555465  0.04445355]\n",
      " [0.9547915  0.04520854]\n",
      " [0.0172154  0.98278457]\n",
      " [0.9618001  0.03819985]\n",
      " [0.10996244 0.89003754]\n",
      " [0.52803516 0.4719649 ]\n",
      " [0.383375   0.61662495]\n",
      " [0.9594777  0.04052226]\n",
      " [0.9601548  0.03984525]\n",
      " [0.14208184 0.85791814]\n",
      " [0.100761   0.89923906]\n",
      " [0.95878977 0.04121028]\n",
      " [0.07047012 0.92952985]\n",
      " [0.03051498 0.96948504]\n",
      " [0.96048915 0.03951083]\n",
      " [0.92836994 0.07163007]\n",
      " [0.96389496 0.0361051 ]\n",
      " [0.96082085 0.0391791 ]\n",
      " [0.16759631 0.83240366]\n",
      " [0.6001314  0.39986855]\n",
      " [0.1544088  0.8455912 ]\n",
      " [0.95591944 0.04408056]\n",
      " [0.95363605 0.04636399]\n",
      " [0.10996244 0.89003754]\n",
      " [0.95809054 0.04190946]\n",
      " [0.9459486  0.05405143]\n",
      " [0.9614763  0.03852362]\n",
      " [0.04048376 0.9595162 ]\n",
      " [0.383375   0.61662495]\n",
      " [0.0172154  0.98278457]\n",
      " [0.96114993 0.03885002]\n",
      " [0.78368515 0.21631491]\n",
      " [0.01894826 0.9810517 ]\n",
      " [0.95975304 0.04024693]\n",
      " [0.03051498 0.96948504]\n",
      " [0.6001314  0.39986855]\n",
      " [0.95347345 0.04652654]\n",
      " [0.04445283 0.95554715]\n",
      " [0.9364828  0.06351724]\n",
      " [0.07047012 0.92952985]\n",
      " [0.03354087 0.9664591 ]\n",
      " [0.95738006 0.04262   ]\n",
      " [0.13058701 0.869413  ]\n",
      " [0.0106346  0.98936546]\n",
      " [0.8670102  0.13298981]\n",
      " [0.8670102  0.13298981]\n",
      " [0.95517045 0.04482952]\n",
      " [0.96258026 0.03741974]\n",
      " [0.07714276 0.9228572 ]\n",
      " [0.02523675 0.9747633 ]\n",
      " [0.31669557 0.68330437]\n",
      " [0.04048376 0.9595162 ]\n",
      " [0.0368554  0.9631446 ]\n",
      " [0.72978234 0.27021766]\n",
      " [0.31669557 0.68330437]\n",
      " [0.383375   0.61662495]\n",
      " [0.8293496  0.17065045]\n",
      " [0.9364828  0.06351724]\n",
      " [0.14208184 0.85791814]\n",
      " [0.941426   0.05857407]\n",
      " [0.78368515 0.21631491]\n",
      " [0.100761   0.89923906]\n",
      " [0.100761   0.89923906]\n",
      " [0.0368554  0.9631446 ]\n",
      " [0.9555465  0.04445355]\n",
      " [0.45475072 0.5452493 ]\n",
      " [0.9566565  0.04334353]\n",
      " [0.04048376 0.9595162 ]\n",
      " [0.96082085 0.0391791 ]\n",
      " [0.01894826 0.9810517 ]\n",
      " [0.9624399  0.03756014]\n",
      " [0.95672184 0.04327813]\n",
      " [0.01563848 0.9843615 ]\n",
      " [0.11989219 0.8801078 ]\n",
      " [0.09224965 0.9077503 ]\n",
      " [0.0368554  0.9631446 ]\n",
      " [0.96048915 0.03951083]\n",
      " [0.02775422 0.9722457 ]\n",
      " [0.02775422 0.9722457 ]\n",
      " [0.95702046 0.04297955]\n",
      " [0.20480862 0.79519135]\n",
      " [0.9364828  0.06351724]\n",
      " [0.20480862 0.79519135]\n",
      " [0.04048376 0.9595162 ]\n",
      " [0.1544088  0.8455912 ]\n",
      " [0.0368554  0.9631446 ]\n",
      " [0.01420391 0.9857961 ]\n",
      " [0.95517045 0.04482952]\n",
      " [0.95347345 0.04652654]\n",
      " [0.03051498 0.96948504]\n",
      " [0.9627558  0.03724413]\n",
      " [0.9170504  0.08294952]\n",
      " [0.78368515 0.21631491]\n",
      " [0.16759631 0.83240366]\n",
      " [0.95517045 0.04482952]\n",
      " [0.02085187 0.97914815]\n",
      " [0.95517045 0.04482952]\n",
      " [0.9547915  0.04520854]\n",
      " [0.9544094  0.04559061]\n",
      " [0.31669557 0.68330437]\n",
      " [0.95773673 0.04226329]\n",
      " [0.941426   0.05857407]\n",
      " [0.9584415  0.04155846]\n",
      " [0.96082085 0.0391791 ]\n",
      " [0.9591351  0.04086489]\n",
      " [0.9601548  0.03984525]\n",
      " [0.95773673 0.04226329]\n",
      " [0.08438983 0.9156102 ]\n",
      " [0.9591351  0.04086489]\n",
      " [0.95517045 0.04482952]\n",
      " [0.96258026 0.03741974]\n",
      " [0.01563848 0.9843615 ]\n",
      " [0.96368355 0.03631642]\n",
      " [0.9624399  0.03756014]\n",
      " [0.9544094  0.04559061]\n",
      " [0.01171295 0.98828703]\n",
      " [0.9638545  0.03614544]\n",
      " [0.96389496 0.0361051 ]\n",
      " [0.96389496 0.0361051 ]\n",
      " [0.10996244 0.89003754]\n",
      " [0.02294223 0.9770578 ]\n",
      " [0.01420391 0.9857961 ]\n",
      " [0.01171295 0.98828703]\n",
      " [0.6001314  0.39986855]\n",
      " [0.9630693  0.0369307 ]\n",
      " [0.9624399  0.03756014]\n",
      " [0.9555465  0.04445355]\n",
      " [0.03051498 0.96948504]\n",
      " [0.96082085 0.0391791 ]\n",
      " [0.01420391 0.9857961 ]\n",
      " [0.95773673 0.04226329]\n",
      " [0.95363605 0.04636399]\n",
      " [0.1544088  0.8455912 ]\n",
      " [0.2567836  0.74321634]\n",
      " [0.6681356  0.3318644 ]\n",
      " [0.9633802  0.03661981]\n",
      " [0.04445283 0.95554715]\n",
      " [0.9584415  0.04155846]\n",
      " [0.95347345 0.04652654]\n",
      " [0.100761   0.89923906]\n",
      " [0.04048376 0.9595162 ]\n",
      " [0.05352941 0.9464706 ]\n",
      " [0.01420391 0.9857961 ]\n",
      " [0.2567836  0.74321634]\n",
      " [0.78368515 0.21631491]\n",
      " [0.9566565  0.04334353]\n",
      " [0.9555465  0.04445355]\n",
      " [0.9627558  0.03724413]\n",
      " [0.07047012 0.92952985]\n",
      " [0.9547915  0.04520854]\n",
      " [0.95672184 0.04327813]\n",
      " [0.95702046 0.04297955]\n",
      " [0.96258026 0.03741974]\n",
      " [0.14208184 0.85791814]\n",
      " [0.01563848 0.9843615 ]\n",
      " [0.96114993 0.03885002]\n",
      " [0.9598176  0.04018238]\n",
      " [0.0172154  0.98278457]\n",
      " [0.03051498 0.96948504]\n",
      " [0.95591944 0.04408056]\n",
      " [0.03354087 0.9664591 ]\n",
      " [0.01171295 0.98828703]\n",
      " [0.95702046 0.04297955]\n",
      " [0.0172154  0.98278457]\n",
      " [0.02523675 0.9747633 ]\n",
      " [0.2567836  0.74321634]\n",
      " [0.95878977 0.04121028]\n",
      " [0.72978234 0.27021766]\n",
      " [0.04048376 0.9595162 ]\n",
      " [0.04048376 0.9595162 ]\n",
      " [0.9566565  0.04334353]\n",
      " [0.96048915 0.03951083]\n",
      " [0.96114993 0.03885002]\n",
      " [0.9562894  0.04371057]\n",
      " [0.9544094  0.04559061]\n",
      " [0.9459486  0.05405143]\n",
      " [0.31669557 0.68330437]\n",
      " [0.31669557 0.68330437]\n",
      " [0.07047012 0.92952985]\n",
      " [0.01420391 0.9857961 ]\n",
      " [0.03354087 0.9664591 ]\n",
      " [0.95591944 0.04408056]\n",
      " [0.6001314  0.39986855]\n",
      " [0.92836994 0.07163007]\n",
      " [0.96258026 0.03741974]\n",
      " [0.100761   0.89923906]\n",
      " [0.9624399  0.03756014]\n",
      " [0.05352941 0.9464706 ]\n",
      " [0.96393526 0.03606478]\n",
      " [0.01420391 0.9857961 ]\n",
      " [0.96258026 0.03741974]\n",
      " [0.02085187 0.97914815]\n",
      " [0.9591351  0.04086489]\n",
      " [0.9547915  0.04520854]\n",
      " [0.0368554  0.9631446 ]\n",
      " [0.0368554  0.9631446 ]\n",
      " [0.96393526 0.03606478]\n",
      " [0.01563848 0.9843615 ]\n",
      " [0.96212137 0.0378787 ]\n",
      " [0.0368554  0.9631446 ]\n",
      " [0.01894826 0.9810517 ]\n",
      " [0.01894826 0.9810517 ]\n",
      " [0.95702046 0.04297955]\n",
      " [0.92836994 0.07163007]\n",
      " [0.02294223 0.9770578 ]\n",
      " [0.9614763  0.03852362]\n",
      " [0.02294223 0.9770578 ]\n",
      " [0.04048376 0.9595162 ]\n",
      " [0.9627558  0.03724413]\n",
      " [0.05869924 0.94130075]\n",
      " [0.11989219 0.8801078 ]\n",
      " [0.8293496  0.17065045]\n",
      " [0.01289922 0.98710084]\n",
      " [0.07047012 0.92952985]\n",
      " [0.11989219 0.8801078 ]\n",
      " [0.9601548  0.03984525]\n",
      " [0.9614763  0.03852362]\n",
      " [0.05869924 0.94130075]\n",
      " [0.05352941 0.9464706 ]\n",
      " [0.9638142  0.03618585]\n",
      " [0.01171295 0.98828703]\n",
      " [0.8670102  0.13298981]\n",
      " [0.96258026 0.03741974]\n",
      " [0.06433444 0.9356655 ]\n",
      " [0.9627558  0.03724413]\n",
      " [0.14208184 0.85791814]\n",
      " [0.02523675 0.9747633 ]\n",
      " [0.52803516 0.4719649 ]\n",
      " [0.16759631 0.83240366]\n",
      " [0.8670102  0.13298981]\n",
      " [0.9555465  0.04445355]\n",
      " [0.9540242  0.04597574]\n",
      " [0.95809054 0.04190946]\n",
      " [0.96258026 0.03741974]\n",
      " [0.9633802  0.03661981]\n",
      " [0.95363605 0.04636399]\n",
      " [0.04048376 0.9595162 ]\n",
      " [0.9555465  0.04445355]\n",
      " [0.2567836  0.74321634]\n",
      " [0.05869924 0.94130075]\n",
      " [0.9544094  0.04559061]\n",
      " [0.07047012 0.92952985]\n",
      " [0.13058701 0.869413  ]\n",
      " [0.9547915  0.04520854]\n",
      " [0.03051498 0.96948504]\n",
      " [0.02523675 0.9747633 ]\n",
      " [0.96082085 0.0391791 ]\n",
      " [0.01420391 0.9857961 ]\n",
      " [0.20480862 0.79519135]\n",
      " [0.05869924 0.94130075]\n",
      " [0.04048376 0.9595162 ]\n",
      " [0.10996244 0.89003754]\n",
      " [0.9540242  0.04597574]\n",
      " [0.8670102  0.13298981]\n",
      " [0.01171295 0.98828703]\n",
      " [0.01420391 0.9857961 ]\n",
      " [0.9638142  0.03618585]\n",
      " [0.8973438  0.10265615]\n",
      " [0.9594777  0.04052226]\n",
      " [0.96258026 0.03741974]\n",
      " [0.96212137 0.0378787 ]\n",
      " [0.9584415  0.04155846]\n",
      " [0.02294223 0.9770578 ]\n",
      " [0.01171295 0.98828703]\n",
      " [0.9544094  0.04559061]\n",
      " [0.04445283 0.95554715]\n",
      " [0.01563848 0.9843615 ]\n",
      " [0.31669557 0.68330437]\n",
      " [0.95773673 0.04226329]\n",
      " [0.9614763  0.03852362]\n",
      " [0.9598176  0.04018238]\n",
      " [0.9540242  0.04597574]\n",
      " [0.95363605 0.04636399]\n",
      " [0.04879128 0.9512087 ]\n",
      " [0.07047012 0.92952985]\n",
      " [0.31669557 0.68330437]\n",
      " [0.08438983 0.9156102 ]\n",
      " [0.11989219 0.8801078 ]\n",
      " [0.96114993 0.03885002]\n",
      " [0.95591944 0.04408056]\n",
      " [0.0172154  0.98278457]\n",
      " [0.04879128 0.9512087 ]\n",
      " [0.95738006 0.04262   ]\n",
      " [0.0368554  0.9631446 ]\n",
      " [0.941426   0.05857407]\n",
      " [0.95347345 0.04652654]\n",
      " [0.02775422 0.9722457 ]\n",
      " [0.05869924 0.94130075]\n",
      " [0.95975304 0.04024693]\n",
      " [0.9633802  0.03661981]\n",
      " [0.94999397 0.05000604]\n",
      " [0.02523675 0.9747633 ]\n",
      " [0.05352941 0.9464706 ]\n",
      " [0.07714276 0.9228572 ]\n",
      " [0.9633802  0.03661981]\n",
      " [0.0368554  0.9631446 ]\n",
      " [0.04445283 0.95554715]\n",
      " [0.8973438  0.10265615]\n",
      " [0.9614763  0.03852362]\n",
      " [0.9618001  0.03819985]\n",
      " [0.09224965 0.9077503 ]\n",
      " [0.07047012 0.92952985]\n",
      " [0.31669557 0.68330437]\n",
      " [0.0368554  0.9631446 ]\n",
      " [0.02085187 0.97914815]\n",
      " [0.02523675 0.9747633 ]\n",
      " [0.9627558  0.03724413]\n",
      " [0.9170504  0.08294952]\n",
      " [0.02523675 0.9747633 ]\n",
      " [0.05869924 0.94130075]\n",
      " [0.95347345 0.04652654]\n",
      " [0.01420391 0.9857961 ]\n",
      " [0.52803516 0.4719649 ]\n",
      " [0.6001314  0.39986855]\n",
      " [0.383375   0.61662495]\n",
      " [0.31669557 0.68330437]\n",
      " [0.04879128 0.9512087 ]\n",
      " [0.31669557 0.68330437]\n",
      " [0.08438983 0.9156102 ]\n",
      " [0.95738006 0.04262   ]\n",
      " [0.96212137 0.0378787 ]\n",
      " [0.02294223 0.9770578 ]\n",
      " [0.13058701 0.869413  ]\n",
      " [0.07047012 0.92952985]\n",
      " [0.95738006 0.04262   ]\n",
      " [0.9633802  0.03661981]\n",
      " [0.0106346  0.98936546]\n",
      " [0.0368554  0.9631446 ]\n",
      " [0.92836994 0.07163007]\n",
      " [0.0172154  0.98278457]\n",
      " [0.0106346  0.98936546]\n",
      " [0.03354087 0.9664591 ]\n",
      " [0.13058701 0.869413  ]\n",
      " [0.96393526 0.03606478]\n",
      " [0.20480862 0.79519135]\n",
      " [0.9364828  0.06351724]\n",
      " [0.95591944 0.04408056]\n",
      " [0.05352941 0.9464706 ]\n",
      " [0.9633802  0.03661981]\n",
      " [0.04048376 0.9595162 ]\n",
      " [0.9170504  0.08294952]\n",
      " [0.95809054 0.04190946]\n",
      " [0.03051498 0.96948504]\n",
      " [0.1544088  0.8455912 ]\n",
      " [0.14208184 0.85791814]\n",
      " [0.11989219 0.8801078 ]\n",
      " [0.13058701 0.869413  ]\n",
      " [0.8973438  0.10265615]\n",
      " [0.16759631 0.83240366]\n",
      " [0.07047012 0.92952985]\n",
      " [0.09224965 0.9077503 ]\n",
      " [0.09224965 0.9077503 ]\n",
      " [0.9364828  0.06351724]\n",
      " [0.10996244 0.89003754]\n",
      " [0.941426   0.05857407]\n",
      " [0.04879128 0.9512087 ]\n",
      " [0.96258026 0.03741974]\n",
      " [0.95591944 0.04408056]\n",
      " [0.100761   0.89923906]\n",
      " [0.9618001  0.03819985]\n",
      " [0.01894826 0.9810517 ]\n",
      " [0.9562894  0.04371057]\n",
      " [0.01420391 0.9857961 ]\n",
      " [0.0368554  0.9631446 ]\n",
      " [0.96212137 0.0378787 ]\n",
      " [0.02294223 0.9770578 ]\n",
      " [0.03354087 0.9664591 ]\n",
      " [0.9562894  0.04371057]\n",
      " [0.0368554  0.9631446 ]\n",
      " [0.45475072 0.5452493 ]\n",
      " [0.9584415  0.04155846]\n",
      " [0.95672184 0.04327813]\n",
      " [0.9544094  0.04559061]\n",
      " [0.95975304 0.04024693]\n",
      " [0.95363605 0.04636399]\n",
      " [0.9591351  0.04086489]\n",
      " [0.9614763  0.03852362]\n",
      " [0.9544094  0.04559061]\n",
      " [0.0368554  0.9631446 ]\n",
      " [0.96212137 0.0378787 ]\n",
      " [0.95975304 0.04024693]\n",
      " [0.95975304 0.04024693]\n",
      " [0.01171295 0.98828703]\n",
      " [0.14208184 0.85791814]\n",
      " [0.05352941 0.9464706 ]\n",
      " [0.02294223 0.9770578 ]\n",
      " [0.9627558  0.03724413]\n",
      " [0.92836994 0.07163007]]\n"
     ]
    }
   ],
   "source": [
    "# [No_side_effect (0), have side effect (1)]\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_pred = np.argmax(pred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_labels, y_pred=rounded_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                         normalize=False,\n",
    "                         title='Confusion matrix',\n",
    "                         cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalisation can be applied by setting 'normalize=True'\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    else:\n",
    "        print('Confusion matrix without normalisation')\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                horizontalalignment='center',\n",
    "                color='white' if cm[i,j] > thresh else 'black')\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix without normalisation\n",
      "[[200  10]\n",
      " [ 10 200]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = ['no_side_effects', 'had_side_effects']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels,  title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Saving and Loading Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This save function saves\n",
    "1. The architecture of the model, allowing to recreate the model\n",
    "2. the weights of the model\n",
    "3. the training configuration (loss, optimizer)\n",
    "4. the state of the optimizer allowing to resume exactly where you left off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_path = 'models/medical_trial_model.h5'\n",
    "if os.path.isfile(model_path) is False:\n",
    "    model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.00395543,  0.6286578 , -0.02848798,  0.1017203 ,  0.34757647,\n",
       "          0.68520474,  0.39806825, -0.38702235,  0.5097547 , -0.41450876,\n",
       "          0.39024994, -0.17077419,  0.62670386, -0.06987685,  0.35413685,\n",
       "         -0.25582993]], dtype=float32),\n",
       " array([-0.00499939, -0.2417226 ,  0.        ,  0.19326815, -0.17365158,\n",
       "        -0.2638279 , -0.19427952,  0.        , -0.2540262 ,  0.        ,\n",
       "        -0.18568188,  0.        , -0.06440621,  0.        ,  0.17236754,\n",
       "         0.        ], dtype=float32),\n",
       " array([[ 2.71255523e-01, -3.46494198e-01,  9.34202522e-02,\n",
       "         -2.35256970e-01, -1.17793128e-01,  2.18004510e-01,\n",
       "          1.68987766e-01,  9.58427265e-02,  1.18798733e-01,\n",
       "          8.19204152e-02, -1.05442986e-01,  1.58158973e-01,\n",
       "          1.24290794e-01,  7.06702471e-02, -2.30269626e-01,\n",
       "          4.13895547e-02, -1.26193032e-01,  1.32751539e-01,\n",
       "         -6.00056909e-02,  1.66974932e-01,  2.15028942e-01,\n",
       "         -9.32951644e-02, -1.65538400e-01, -1.42173365e-01,\n",
       "          2.94000417e-01,  1.46530360e-01, -1.23463444e-01,\n",
       "         -1.91783071e-01, -3.40462416e-01,  3.27305108e-01,\n",
       "         -2.22166061e-01,  1.58148378e-01],\n",
       "        [-6.59536242e-01,  1.62224770e-02,  3.74650121e-01,\n",
       "         -1.94568425e-01,  3.24217021e-01,  4.49140191e-01,\n",
       "         -1.04320481e-01,  2.32249022e-01, -1.65212363e-01,\n",
       "         -4.76166397e-01, -1.37307435e-01, -2.99802274e-01,\n",
       "         -2.78071910e-01, -1.35766208e-01,  2.30380073e-01,\n",
       "         -5.02686441e-01,  2.40650490e-01,  2.80371178e-02,\n",
       "         -4.52330142e-01, -6.19927049e-01,  6.00760043e-01,\n",
       "          4.91435617e-01, -6.80640459e-01, -3.38601887e-01,\n",
       "         -3.17371100e-01,  4.19434845e-01, -6.69271350e-01,\n",
       "          2.49374270e-01,  3.69493902e-01,  1.56232804e-01,\n",
       "         -2.31043145e-01, -2.98490554e-01],\n",
       "        [-2.60845751e-01, -1.20516717e-01,  1.95859462e-01,\n",
       "          1.70405179e-01,  4.09346819e-03,  2.57268995e-01,\n",
       "         -1.74512655e-01, -7.00470805e-03, -3.76976728e-02,\n",
       "          1.75924331e-01, -2.97603518e-01,  1.10013306e-01,\n",
       "          3.04096669e-01, -2.61594772e-01, -2.83209532e-01,\n",
       "          1.72358364e-01,  1.46976024e-01,  1.30963415e-01,\n",
       "         -2.09196463e-01, -2.24997744e-01,  2.76579350e-01,\n",
       "         -9.09647942e-02,  1.90843314e-01, -1.26262426e-01,\n",
       "          1.46312624e-01,  2.59317189e-01,  1.38944417e-01,\n",
       "         -3.58626246e-03,  2.75418252e-01,  2.90691853e-02,\n",
       "          1.02256924e-01,  7.73660243e-02],\n",
       "        [ 3.29596549e-01, -1.13630846e-01,  3.72301579e-01,\n",
       "          2.60347128e-01, -4.52893376e-02, -5.45693822e-02,\n",
       "          3.02400440e-01, -3.62501949e-01,  2.66191900e-01,\n",
       "          2.18690246e-01,  2.00687200e-01,  3.66065472e-01,\n",
       "          1.05109185e-01, -4.87216711e-02, -8.05253908e-02,\n",
       "          3.54406357e-01,  2.37428963e-01,  1.60759732e-01,\n",
       "          1.27526209e-01,  3.83833230e-01, -1.43699840e-01,\n",
       "          3.47311378e-01,  4.09579396e-01, -2.00181589e-01,\n",
       "          1.23679787e-01, -2.81669069e-02,  2.62458771e-02,\n",
       "         -1.43373698e-01,  1.38130680e-01,  2.92134345e-01,\n",
       "          2.90810138e-01, -1.79620683e-02],\n",
       "        [-3.79051477e-01, -1.43622711e-01,  1.13424383e-01,\n",
       "         -3.10774177e-01,  2.11054057e-01,  3.01471442e-01,\n",
       "          2.29756489e-01,  2.25961164e-01, -5.87901354e-01,\n",
       "         -8.15628231e-01, -3.53208125e-01, -4.04706925e-01,\n",
       "         -9.31319594e-02, -3.36095393e-01,  5.72120309e-01,\n",
       "         -3.18870753e-01, -4.74641547e-02, -3.99256200e-01,\n",
       "         -5.89435339e-01, -8.44394028e-01,  2.17981577e-01,\n",
       "          2.40042463e-01, -9.56983745e-01,  7.57082105e-02,\n",
       "         -3.01255673e-01,  5.85741818e-01, -5.74185312e-01,\n",
       "          1.00530684e-01,  4.06918854e-01, -2.45532945e-01,\n",
       "         -8.47557068e-01, -1.51612669e-01],\n",
       "        [-6.46516383e-01,  7.58998990e-02,  4.25853103e-01,\n",
       "          1.67626768e-01,  1.65694356e-01,  2.80129582e-01,\n",
       "          1.29650161e-01,  1.44134447e-01, -3.91500831e-01,\n",
       "         -5.09549260e-01,  7.23044276e-02, -7.71322697e-02,\n",
       "          3.40730637e-01, -1.39555126e-01,  6.32234097e-01,\n",
       "         -7.16650546e-01, -2.06956983e-01, -1.11028545e-01,\n",
       "         -1.02687329e-01, -1.92045331e-01,  4.03852642e-01,\n",
       "          1.78893045e-01, -3.60318214e-01,  3.08165163e-01,\n",
       "         -7.35143483e-01,  3.38146575e-02, -6.41658545e-01,\n",
       "         -3.21184069e-01,  3.38447392e-02,  1.77284971e-01,\n",
       "         -5.50794661e-01, -2.36884758e-01],\n",
       "        [-1.80248916e-01, -7.78015554e-02,  5.56384623e-01,\n",
       "         -2.22110540e-01,  5.17901719e-01,  2.21740723e-01,\n",
       "         -9.36208963e-02, -3.67409557e-01, -2.37196788e-01,\n",
       "         -8.58912408e-01, -1.07587844e-01, -4.44540173e-01,\n",
       "          1.13374501e-01, -2.70927101e-01,  5.91489434e-01,\n",
       "         -4.08070087e-01,  6.61510229e-03, -2.95181185e-01,\n",
       "         -3.50402027e-01, -2.10084796e-01,  9.94419605e-02,\n",
       "          4.12548214e-01, -2.92266279e-01, -4.79290485e-02,\n",
       "         -7.73132801e-01,  2.79815465e-01, -3.97142142e-01,\n",
       "         -2.70472348e-01,  3.43179852e-01,  2.54281819e-01,\n",
       "         -4.75421160e-01,  2.48458058e-01],\n",
       "        [-1.38336912e-01,  1.50790781e-01, -1.04288325e-01,\n",
       "          7.84538388e-02, -2.11540341e-01, -1.30649924e-01,\n",
       "         -9.79807973e-02, -1.46714687e-01, -1.82375312e-02,\n",
       "         -1.63784847e-01, -3.31355751e-01, -3.34971607e-01,\n",
       "          2.15294689e-01, -1.04822412e-01, -3.40067148e-01,\n",
       "          2.76713341e-01, -2.34547377e-01,  1.37850791e-01,\n",
       "          2.45747238e-01,  1.62347943e-01, -3.50929588e-01,\n",
       "          5.62937856e-02,  1.51651889e-01, -7.07646310e-02,\n",
       "         -2.98409969e-01, -3.10218632e-02, -1.27095163e-01,\n",
       "          1.59387082e-01, -8.99488032e-02,  3.21171194e-01,\n",
       "          2.48860627e-01,  2.32957870e-01],\n",
       "        [-8.86316121e-01,  4.83294427e-02, -9.32598778e-04,\n",
       "          1.48242041e-02,  4.91488338e-01,  3.70759755e-01,\n",
       "          2.10148126e-01,  9.64282826e-02, -8.22692752e-01,\n",
       "         -8.71071815e-01,  2.31598616e-02, -5.72079599e-01,\n",
       "         -7.05692470e-02, -1.76859051e-01,  4.94827181e-01,\n",
       "         -4.69789393e-02, -9.26447436e-02, -5.66337705e-01,\n",
       "         -4.02858645e-01, -9.28091705e-01,  1.94671452e-01,\n",
       "          1.93736672e-01, -8.07267368e-01,  2.76008397e-01,\n",
       "         -4.71469730e-01,  2.33102083e-01, -3.84344548e-01,\n",
       "         -1.27731308e-01,  1.57400250e-01,  9.10305083e-02,\n",
       "         -7.73548484e-01,  2.34153837e-01],\n",
       "        [ 1.68566734e-01,  1.85105413e-01,  3.04590911e-01,\n",
       "          1.37964576e-01, -1.80368617e-01,  1.58247322e-01,\n",
       "         -1.76522210e-01, -1.58783197e-01, -5.28634489e-02,\n",
       "          3.38090360e-02, -3.13899934e-01, -2.32015103e-01,\n",
       "          7.39872456e-03,  9.39542651e-02, -2.72221178e-01,\n",
       "         -1.34411529e-01, -3.09838921e-01, -1.69594958e-01,\n",
       "         -3.21830958e-01,  1.47014469e-01, -2.87231088e-01,\n",
       "          1.29324198e-02, -2.79060304e-02, -1.54806077e-02,\n",
       "         -6.95550144e-02, -2.10695714e-01, -4.92953658e-02,\n",
       "          3.39974254e-01, -8.01806748e-02, -2.70460188e-01,\n",
       "          2.09853262e-01, -1.52186289e-01],\n",
       "        [-4.18897361e-01, -2.46591002e-01,  5.81932425e-01,\n",
       "          6.41116779e-03,  4.21150178e-01,  5.30216575e-01,\n",
       "          2.23413795e-01,  9.17668920e-03, -5.48700929e-01,\n",
       "         -6.80383071e-02,  3.05428207e-02, -6.66130364e-01,\n",
       "         -1.79549202e-01,  2.54342765e-01,  4.93411601e-01,\n",
       "         -2.41640478e-01, -3.46438408e-01, -1.37287930e-01,\n",
       "         -2.34355107e-01, -3.94145936e-01,  4.27378982e-01,\n",
       "          5.52788258e-01, -4.84491497e-01, -2.19008505e-01,\n",
       "         -3.47262889e-01,  5.91245174e-01, -2.42580742e-01,\n",
       "         -4.63354215e-03,  1.13428414e-01, -3.65338534e-01,\n",
       "         -4.85857666e-01,  2.03225315e-02],\n",
       "        [ 2.74485618e-01, -1.47952437e-02, -2.48897284e-01,\n",
       "          2.36508816e-01, -7.84015656e-02,  4.40471768e-02,\n",
       "         -3.30801338e-01,  1.49231851e-02, -2.23049045e-01,\n",
       "         -2.70894140e-01, -2.61464030e-01,  2.40810901e-01,\n",
       "          3.13286781e-02, -4.12202775e-02,  3.26811284e-01,\n",
       "         -1.56761572e-01, -3.20177287e-01, -2.88751006e-01,\n",
       "          5.20488322e-02, -3.52881044e-01,  1.40462637e-01,\n",
       "         -1.83172807e-01, -9.99227166e-03, -7.09571540e-02,\n",
       "         -2.12225303e-01, -3.09652060e-01, -8.59651566e-02,\n",
       "         -3.37584019e-01,  3.12348604e-02,  2.31387466e-01,\n",
       "          1.35382503e-01,  3.00897449e-01],\n",
       "        [-2.45457023e-01, -1.06350318e-01,  5.03841102e-01,\n",
       "          2.37206861e-01,  1.98022902e-01,  3.92330140e-01,\n",
       "         -3.48285109e-01,  1.51808098e-01,  2.48172693e-02,\n",
       "          7.62333199e-02, -4.91323471e-02,  3.81069146e-02,\n",
       "         -2.63532758e-01, -2.20748916e-01,  2.88736016e-01,\n",
       "         -2.32734844e-01,  2.52334606e-02, -5.44321239e-02,\n",
       "         -8.79120305e-02, -1.07636392e-01,  2.09798202e-01,\n",
       "          8.58127978e-03,  1.99692622e-02, -1.00081831e-01,\n",
       "         -1.99428111e-01,  4.74816978e-01,  1.59435183e-01,\n",
       "          9.55484584e-02,  3.91068339e-01, -1.65119186e-01,\n",
       "         -1.23563670e-01,  1.91831023e-01],\n",
       "        [ 4.66428995e-02,  6.39855862e-03,  5.81524372e-02,\n",
       "          6.83249235e-02,  2.91704386e-01, -3.48832011e-01,\n",
       "          2.50042409e-01, -1.81095138e-01, -3.10667694e-01,\n",
       "         -8.15474987e-03,  3.84455025e-02,  1.67913139e-02,\n",
       "         -2.76522696e-01,  1.52045697e-01, -5.88643253e-02,\n",
       "          2.38830656e-01, -2.24078268e-01, -3.01270902e-01,\n",
       "         -3.36368263e-01,  2.58332163e-01, -4.87805903e-02,\n",
       "         -1.64250433e-02, -1.26267150e-01,  2.61940569e-01,\n",
       "          2.52792925e-01,  3.06872815e-01,  3.09368044e-01,\n",
       "         -4.32309508e-03, -1.41734704e-01,  2.33077735e-01,\n",
       "          3.09398264e-01, -1.87040880e-01],\n",
       "        [ 3.33773822e-01, -1.61227539e-01, -7.89346173e-02,\n",
       "         -3.43249440e-01,  4.59357873e-02, -2.89003644e-02,\n",
       "         -3.38897377e-01, -2.72032201e-01, -2.69049499e-02,\n",
       "          2.11410075e-01, -2.70439982e-01, -1.28989741e-01,\n",
       "         -1.74318105e-01, -1.65595725e-01,  1.40501663e-01,\n",
       "         -1.27026796e-01, -3.37248556e-02,  1.17921889e-01,\n",
       "          1.72444135e-01, -3.28274891e-02,  3.27407449e-01,\n",
       "          2.69010924e-02,  7.59554580e-02, -1.91104516e-01,\n",
       "          2.24033654e-01,  2.85759032e-01,  2.82073408e-01,\n",
       "          7.33737573e-02,  2.62781024e-01, -2.03717485e-01,\n",
       "          1.18069537e-01, -2.79181570e-01],\n",
       "        [ 1.25995129e-01,  1.08117610e-01, -1.67470410e-01,\n",
       "          8.49705040e-02,  4.69587445e-02,  1.33710712e-01,\n",
       "         -2.04879954e-01,  2.07264870e-01,  3.18692058e-01,\n",
       "          1.46956056e-01, -1.31674409e-02, -1.77010000e-02,\n",
       "          2.53830999e-01, -1.99061081e-01,  5.21025956e-02,\n",
       "          3.39920670e-01,  2.07388431e-01,  2.45366067e-01,\n",
       "          2.62886852e-01,  2.95388609e-01, -3.22186947e-01,\n",
       "         -2.18833938e-01, -2.91529566e-01,  2.73478001e-01,\n",
       "         -2.36514360e-01, -2.01846361e-02,  1.82837218e-01,\n",
       "          1.35934383e-01,  1.55035228e-01, -2.15065926e-01,\n",
       "          2.94650197e-02,  2.92719215e-01]], dtype=float32),\n",
       " array([ 0.22797921,  0.        , -0.15317988, -0.00306144, -0.07779314,\n",
       "        -0.10776802, -0.00077738, -0.01917741,  0.17965366,  0.18017817,\n",
       "         0.        ,  0.14379431,  0.        ,  0.        , -0.14460652,\n",
       "         0.12043396, -0.05826461,  0.03505656,  0.11792765,  0.24829087,\n",
       "        -0.15426138, -0.13270496,  0.20712179,  0.        ,  0.03943435,\n",
       "        -0.14783426,  0.16065802, -0.01172707, -0.16402051, -0.02265548,\n",
       "         0.23025464,  0.        ], dtype=float32),\n",
       " array([[ 0.86477035, -0.34649596],\n",
       "        [ 0.16138473, -0.39360362],\n",
       "        [-0.5578154 ,  0.02747864],\n",
       "        [-0.15049163,  0.41603482],\n",
       "        [-0.4220543 ,  0.5898209 ],\n",
       "        [-0.6321703 ,  0.37123302],\n",
       "        [ 0.19599763,  0.2652579 ],\n",
       "        [-0.20595074, -0.30953312],\n",
       "        [ 0.9429489 , -0.43617854],\n",
       "        [ 0.98006016, -0.9793316 ],\n",
       "        [-0.27045882,  0.27684185],\n",
       "        [ 0.49638394, -0.7586027 ],\n",
       "        [-0.05172259, -0.13301116],\n",
       "        [-0.15941364,  0.0503287 ],\n",
       "        [-0.34600955,  0.25797185],\n",
       "        [-0.3990625 ,  0.32468122],\n",
       "        [-0.30307144,  0.04181875],\n",
       "        [ 0.30154628, -0.20644554],\n",
       "        [ 0.5564156 , -0.11076476],\n",
       "        [ 0.8437927 , -0.380818  ],\n",
       "        [-0.6391555 ,  0.2798903 ],\n",
       "        [-0.6518404 ,  0.2731785 ],\n",
       "        [ 0.5904737 , -0.95264304],\n",
       "        [ 0.15059552, -0.41091147],\n",
       "        [-0.18677731,  0.22638524],\n",
       "        [-0.5368556 ,  0.44119987],\n",
       "        [ 0.20084076, -0.7789692 ],\n",
       "        [-0.36838806, -0.01882826],\n",
       "        [-0.49177945,  0.2905603 ],\n",
       "        [ 0.27300948, -0.26953074],\n",
       "        [ 0.4650544 , -0.8241537 ],\n",
       "        [-0.08578047,  0.41456255]], dtype=float32),\n",
       " array([ 0.04424174, -0.0442417 ], dtype=float32)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x1c79d5a9ca0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json\n",
    "if you only want to save the architecture of a model, and not its weights or its training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as Json\n",
    "json_string = model.to_json()\n",
    "\n",
    "# save as yaml\n",
    "#yaml_string = model.to_yaml()\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_input\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.5.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model reconstruction from json\\\n",
    "from tensorflow.keras.models import model_from_json\n",
    "model_archictecture = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_archictecture.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
